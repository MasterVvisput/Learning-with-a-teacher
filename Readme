Вводная информация:

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Задача исследования:

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Для этого мы будем решать задачу классификации методом машинного обучения с учителем.

Цель исследования:

Построить модель с предельно большим значением F1-меры. Нужно довести метрику до 0.59.
Проверить F1-меру на тестовой выборке.
Дополнительно измерить AUC-ROC, сравнить её значение с F1-мерой.
Описание данных:

Источник данных: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling
Нам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.
Признаки:

RowNumber — индекс строки в данных
CustomerId — уникальный идентификатор клиента
Surname — фамилия
CreditScore — кредитный рейтинг
Geography — страна проживания
Gender — пол
Age — возраст
Tenure — сколько лет человек является клиентом банка
Balance — баланс на счёте
NumOfProducts — количество продуктов банка, используемых клиентом
HasCrCard — наличие кредитной карты
IsActiveMember — активность клиента
EstimatedSalary — предполагаемая зарплата

Целевой признак:

Exited — факт ухода клиента

Мы выполнили подготовку данных:

Мы создали датафрейм data, содержащий в себе все данные исходного файла
Данные содержат 10000 объектов - пользователей банка.
Датафрейм содержит пропуски в колонке "Tenure" в количестве: 909
Мы не нашли, чем можно заполнить пропуски и удалили 909 строк из исходного датафрейма
Мы привели название колонок датафрейма к общему стандарту (все названия с маленькой буквы, слова разделены нижним подчеркиванием)
Мы проверили датафрейм на дубли и не обнаружили их.
Мы удалили колонку row_number так как она не содержит в себе информации о пользователе.
Мы удалили колонку customer_id так как она не содержит в себе информации о пользователе.
Мы удалили колонку surname так как она не содержит в себе информации о пользователе.
Мы вывели корреляцию признаков. Сильной корреляции между признаками не обнаружено.
Мы закодировали категориальные данные (Страна проживания, гендер) методом One-Hot Encoding или Прямое кодирование.
Мы выполнили исследование задачи

Мы выяснили, что данные по классам (ушедшие и оставшиеся пользователи) находтся в существенном дисбалансе. 12 процентов данных об ушедших пользователях и 88% об оставшихся.
Мы сформировали тренировочную, валидационную и тестовые выборки в соотношении 3:1:1
Мы изучили три модели обучения: LogisticRegression, DecisionTreeClassifier, RandomForestClassifier.
Лучшие результаты показала последняя подель с значением f1 метрики: 0.5860306643952299, при best_n_estimators 11, best_max_depth 9
Мы выполнили стандартизацию данных с целью улучшить качество прогнозов моделей. Стандартизация не принисла положительных или отрийательных результатов. Начения метрик остались неизменными.
Нам не удалось достигнуть необходимых значений f1 метрики, 0.59. Нам стоит обратить внимание на дисбаланс классов и исправить его.
Также, мы получили показатели метрики AUC-ROC и сравнили её с метрикой F1.

Модель LogisticRegression дала результат метрики AUC-ROC 0.79, что на 30% больше случайной модели (показатель 0.5), что подтверждает метрику F1 = 33
Модель DecisionTreeClassifier дала результат метрики AUC-ROC 0.86, что на 36% больше случайной модели (показатель 0.5), что подтверждает метрику F1 = 57
Модель RandomForestClassifier дала результат метрики AUC-ROC 0.87, что на 37% больше случайной модели (показатель 0.5), что подтверждает метрику F1 = 58
Мы провели борьбу с дисбалансом

В исследовании работы с дисбалансом классов, мы применили несколько методик и получили следубщие результаты:

Метод "Взвешивание классов" показал лучший результат метрики f1 на валидационной выборке в модели RandomForestClassifier. С показателями метрики 0.66 и best_n_estimators 41, best_max_depth 9
Метод "Увеличение выборки" показал лучший результат метрики f1 на валидационной выборке в модели RandomForestClassifier. С показателями метрики 0.64 и best_n_estimators 91, best_max_depth 9
Метод "Изменение порога" показал лучший результат метрики f1 на валидационной выборке в модели RandomForestClassifier. С показателями метрики f1 = 64. Порогом вероятности = 0.28. И гиперпараметрами модели best_n_estimators 11, best_max_depth 9
Также, мы получили показатели метрики AUC-ROC и сравнили её с метрикой F1.

Взвешивание классов

Модель LogisticRegression дала результат метрики AUC-ROC 0.79, что на 30% больше случайной модели (показатель 0.5). Однако, не смотря на рост метрики F1 = 0.51, метрика AUC-ROC осталась прежней.
Модель DecisionTreeClassifier дала результат метрики AUC-ROC 0.85. Метрика F1 осталась неизменной = 0.58
Модель RandomForestClassifier дала результат метрики AUC-ROC 0.87, что на 37% больше случайной модели (показатель 0.5), Однако, не смотря на рост метрики F1 = 0.66, метрика AUC-ROC осталась прежней.
Увеличение выборки

Модель LogisticRegression дала результат метрики AUC-ROC 0.75, что на 25% больше случайной модели (показатель 0.5). Однако, не смотря на рост метрики F1 = 0.51, метрика AUC-ROC осталась прежней.
Модель DecisionTreeClassifier дала больший результат метрики AUC-ROC 0.88, чем это было до решения дисбаланса классов или решения дисбаланса классов методом "Взвешивание классов". Метрика F1 тоже выросла = 0.60
Модель RandomForestClassifier дала результат метрики AUC-ROC 0.88, что на 38% больше случайной модели (показатель 0.5), метрика чуть упала, F1 = 0.64
Таким образом, считаем, что наилучших показателей мы добились, используя метод "Взвешивание классов" в модели RandomForestClassifier. С показателями метрики 0.66 и best_n_estimators 41, best_max_depth 9

Мы выполнили тестирование модели

Для тестирования, мы использовали модель RandomForestClassifier С показателями метрики 0.66 и best_n_estimators 41, best_max_depth 9 и методом решения дисбаланса классов "Взвешивание классов".
Тестирование мы провели на ранее подготовленной тестовой выборке: X_test_scaled, y_test
В ходе тестирования, мы получили показатели метрик: F1 = 0.61, auc_roc = 0.87.
Данные показатели являются хорошими показателями прогностической способности модели. Что говорит о ее пригодности к использованию на реальных данных.
